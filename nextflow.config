// Complete nextflow.config for Updated Modules 1 & 2
// Updated: Liftover removed, build tracking added

params {
    // ============================================================================
    // INPUT PARAMETERS
    // ============================================================================
    
    sample_sheet = null  // REQUIRED: Path to sample sheet (TSV with build column)
    outdir = "${launchDir}/results"
    skip_modules = null  // e.g., "5,7" to skip modules 5 and 7
    
    // ============================================================================
    // MODULE 1: PRE-IMPUTATION QC (UPDATED)
    // ============================================================================
    
    // Will Rayner's strand checking
    rayner_script = "${projectDir}/assets/rayner_scripts/HRC-1000G-check-bim.pl"
    
    // BOTH hg19 and hg38 references needed (script selects based on build)
    rayner_ref_hg19 = "${projectDir}/assets/rayner_scripts/PASS.Variants.TOPMed_freeze5_hg19_dbSNP.tab"
    rayner_ref_hg38 = "${projectDir}/assets/rayner_scripts/PASS.Variants.TOPMed_freeze5_hg38_dbSNP.tab"
    
    // QC thresholds
    preqc_geno = 0.05  // SNP missingness threshold
    preqc_mind = 0.05  // Sample missingness threshold
    preqc_maf = 0.01   // MAF filter (optional, not used by default)
    preqc_hwe = 1e-6   // HWE filter (optional, not used by default)
    
    // REMOVED - No longer needed (servers handle liftover):
    // liftover_chain = ...
    // hg38_ref_fasta = ...
    // hg38_ref_fai = ...
    // hg38_ref_dict = ...
    
    // ============================================================================
    // MODULE 2: IMPUTATION (UPDATED)
    // ============================================================================
    
    // Service selection (enable/disable each service)
    run_topmed = true   // Use TOPMed imputation server
    run_anvil = false   // Use All of Us AnVIL imputation (set to true when ready)
    
    // TOPMed Imputation Server credentials
    topmed_api_token = null      // REQUIRED if run_topmed=true
                                 // Get from: https://imputation.biodatacatalyst.nhlbi.nih.gov/
                                 // Or set via: --topmed_api_token or env var IMPUTATION_BOT_API_TOKEN
    
    topmed_password = null       // Optional: password for encrypted results
                                 // If not set, results are still encrypted with auto-generated password
    
    // All of Us AnVIL Imputation Service credentials
    anvil_token = null          // REQUIRED if run_anvil=true
    anvil_workspace = null      // Terra workspace name
    anvil_project = null        // Google Cloud Platform project ID
    
    // ============================================================================
    // MODULE 3: POST-IMPUTATION QC
    // ============================================================================
    
    magicalrsq_threshold = 0.3  // Minimum imputation quality (RÂ²)
    postqc_geno = 0.05          // Variant missingness
    postqc_mind = 0.05          // Sample missingness
    
    // ============================================================================
    // MODULE 4: PLATFORM MERGING
    // ============================================================================
    
    merge_mode = 'union'        // 'union' or 'intersection'
    max_dropped_variants = 200000  // Alert if more variants dropped
    
    // ============================================================================
    // MODULE 5: RE-IMPUTATION
    // ============================================================================
    
    reimpute_topmed = true      // Re-impute merged data with TOPMed
    reimpute_anvil = false      // Re-impute merged data with AnVIL
    
    // ============================================================================
    // MODULE 6: FINAL QC
    // ============================================================================
    
    use_genesis = true          // Use GENESIS for relatedness (vs PLINK)
    
    // GENESIS/PLINK relatedness
    kinship_threshold = 0.0884  // Second-degree relatives (2^(-9/2))
    king_cutoff = 0.0884        // KING-robust cutoff
    
    // Hardy-Weinberg Equilibrium
    hwe_threshold = 1e-10       // HWE p-value threshold
    hwe_mode = 'midp'           // 'midp' or 'exact'
    
    // Heterozygosity
    het_sd_threshold = 3        // SD from mean F coefficient
    
    // Final MAF filters
    maf_common = 0.01           // Common variants
    maf_analysis = 0.05         // Analysis variants
    
    // ============================================================================
    // MODULE 7: ANCESTRY ESTIMATION
    // ============================================================================
    
    // Reference panel for ancestry
    reference_panel = "${projectDir}/assets/reference_panels/HGDP_1KG/joint_called.rds"
    
    // GRAF-pop/Graf-anc
    run_grafpop = true
    grafpop_mode = 'population'  // 'population' or 'subject'
    
    // ADMIXTURE
    run_admixture = true
    admixture_k = "5,6,7"       // K values to test
    
    // RFMix (local ancestry)
    run_rfmix = true
    genetic_map = "${projectDir}/assets/reference_panels/genetic_maps"
    rfmix_reference = "${projectDir}/assets/reference_panels/tractor_references"
    rfmix_generations = 8       // Generations since admixture
}

// ============================================================================
// PROCESS RESOURCE ALLOCATION
// ============================================================================

process {
    // Default for all processes
    cpus = 1
    memory = '4.GB'
    time = '2.h'
    
    // Module 1: Pre-imputation QC
    withLabel: 'preqc' {
        cpus = 4
        memory = '16.GB'
        time = '4.h'
    }
    
    // Module 1: Liftover (REMOVED - no longer used)
    // withLabel: 'liftover' { ... }
    
    // Module 1 & 2: BCFtools operations
    withLabel: 'bcftools' {
        cpus = 4
        memory = '16.GB'
        time = '4.h'
    }
    
    // Module 2: API calls
    withLabel: 'api' {
        cpus = 1
        memory = '4.GB'
        time = '2.h'
        maxRetries = 3
    }
    
    // Module 2: Download results
    withLabel: 'download' {
        cpus = 2
        memory = '8.GB'
        time = '6.h'
    }
    
    // Module 3: Post-imputation QC
    withLabel: 'postqc' {
        cpus = 8
        memory = '32.GB'
        time = '4.h'
    }
    
    // Module 4: Platform merging
    withLabel: 'plink_merge' {
        cpus = 8
        memory = '64.GB'
        time = '8.h'
    }
    
    // Module 6: GENESIS
    withLabel: 'genesis' {
        cpus = 16
        memory = '64.GB'
        time = '12.h'
    }
    
    // Module 7: RFMix
    withLabel: 'rfmix' {
        cpus = 16
        memory = '32.GB'
        time = '24.h'
    }
}

// ============================================================================
// EXECUTION PROFILES
// ============================================================================

profiles {
    // Standard local execution
    standard {
        process.executor = 'local'
        process.cpus = 4
        process.memory = '16.GB'
    }
    
    // SLURM cluster
    slurm {
        process {
            executor = 'slurm'
            queue = 'normal'
            clusterOptions = '--account=your_account'
        }
        executor {
            queueSize = 100
            submitRateLimit = '10 sec'
        }
    }
    
    // PBS/Torque cluster
    pbs {
        process {
            executor = 'pbs'
            queue = 'batch'
        }
    }
    
    // Docker containers
    docker {
        docker.enabled = true
        docker.runOptions = '-u $(id -u):$(id -g)'
        
        process {
            withLabel: 'preqc' {
                container = 'biocontainers/plink:v1.90b6.21'
            }
            withLabel: 'bcftools' {
                container = 'biocontainers/bcftools:v1.19'
            }
            withLabel: 'api' {
                container = 'python:3.11-slim'
            }
        }
    }
    
    // Singularity containers (for HPC)
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        singularity.cacheDir = "${HOME}/.singularity/cache"
        
        process {
            withLabel: 'preqc' {
                container = 'docker://biocontainers/plink:v1.90b6.21'
            }
            withLabel: 'bcftools' {
                container = 'docker://biocontainers/bcftools:v1.19'
            }
        }
    }
    
    // Conda environments
    conda {
        conda.enabled = true
        conda.createTimeout = '1 h'
        
        process {
            withLabel: 'preqc' {
                conda = "${projectDir}/envs/plink.yml"
            }
            withLabel: 'bcftools' {
                conda = "${projectDir}/envs/plink.yml"
            }
            withLabel: 'api' {
                conda = "${projectDir}/envs/imputation.yml"
            }
            withLabel: 'genesis' {
                conda = "${projectDir}/envs/r_analysis.yml"
            }
        }
    }
    
    // Combined profiles
    'slurm,singularity' {
        includeConfig 'profiles/slurm.config'
        includeConfig 'profiles/singularity.config'
    }
    
    'slurm,conda' {
        includeConfig 'profiles/slurm.config'
        includeConfig 'profiles/conda.config'
    }
    
    // Testing profile (reduced resources)
    test {
        process.cpus = 2
        process.memory = '8.GB'
        process.time = '1.h'
        params.skip_modules = "5,7"  // Skip re-imputation and ancestry
    }
}

// ============================================================================
// REPORTING AND MONITORING
// ============================================================================

timeline {
    enabled = true
    file = "${params.outdir}/reports/timeline.html"
    overwrite = true
}

report {
    enabled = true
    file = "${params.outdir}/reports/report.html"
    overwrite = true
}

trace {
    enabled = true
    file = "${params.outdir}/reports/trace.txt"
    overwrite = true
    fields = 'task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes'
}

dag {
    enabled = true
    file = "${params.outdir}/reports/dag.html"
    overwrite = true
}

// ============================================================================
// WORKFLOW METADATA
// ============================================================================

manifest {
    name = 'Genotyping QC, Imputation, and Ancestry Pipeline'
    author = 'Your Name'
    description = 'Complete pipeline for multi-platform genotyping data'
    mainScript = 'main.nf'
    version = '2.0.0'  // Updated with liftover changes
    nextflowVersion = '>=23.04.0'
}

// ============================================================================
// CLEANUP
// ============================================================================

cleanup = false  // Set to true to automatically delete work directory on success

// ============================================================================
// EXAMPLE USAGE
// ============================================================================

/*
Basic run (TOPMed only):
  nextflow run main.nf \
    --sample_sheet platforms.tsv \
    --run_topmed \
    --topmed_api_token $TOPMED_TOKEN \
    -profile slurm,singularity

Both services:
  nextflow run main.nf \
    --sample_sheet platforms.tsv \
    --run_topmed \
    --run_anvil \
    --topmed_api_token $TOPMED_TOKEN \
    --anvil_workspace my-workspace \
    --anvil_project my-project \
    -profile slurm,conda \
    -resume

Skip modules:
  nextflow run main.nf \
    --sample_sheet platforms.tsv \
    --skip_modules "5,7" \
    --run_topmed \
    --topmed_api_token $TOPMED_TOKEN \
    -resume

Test run:
  nextflow run main.nf \
    --sample_sheet test.tsv \
    -profile test \
    -with-report

Environment variables (alternative to CLI params):
  export IMPUTATION_BOT_API_TOKEN="your-topmed-token"
  nextflow run main.nf \
    --sample_sheet platforms.tsv \
    --run_topmed
*/

// ============================================================================
// IMPORTANT NOTES
// ============================================================================

/*
CHANGES IN VERSION 2.0:
1. REMOVED liftover process from Module 1
   - Imputation servers handle liftover automatically
   - Reduces pipeline complexity
   - Saves disk space (no hg38 reference needed)

2. ADDED build tracking
   - Build info flows through entire pipeline
   - Correct Rayner reference selected per build
   - Build parameter passed to imputation servers

3. UPDATED Module 2
   - Build-aware API submissions
   - Uses Imputation Bot for TOPMed
   - All of Us AnVIL integration (placeholder)

4. REQUIRED FILES:
   - BOTH hg19 and hg38 Rayner references
   - Sample sheet MUST include build column
   - Imputation Bot must be installed

5. DOWNLOAD RAYNER REFERENCES:
   cd assets/rayner_scripts/
   wget http://www.well.ox.ac.uk/~wrayner/tools/PASS.Variants.TOPMed_freeze5_hg19_dbSNP.tab.gz
   wget http://www.well.ox.ac.uk/~wrayner/tools/PASS.Variants.TOPMed_freeze5_hg38_dbSNP.tab.gz
   gunzip *.gz

6. INSTALL IMPUTATION BOT:
   pip install imputationbot
   export IMPUTATION_BOT_API_TOKEN="your-token"
*/
